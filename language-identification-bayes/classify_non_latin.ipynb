{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tira.rest_api_client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tira = Client()\n",
    "   \n",
    "    # loading train data\n",
    "text_train = tira.pd.inputs(\n",
    "        \"nlpbuw-fsu-sose-24\", \"language-identification-train-20240429-training\"\n",
    ")\n",
    "targets_train = tira.pd.truths(\n",
    "        \"nlpbuw-fsu-sose-24\", \"language-identification-train-20240429-training\"\n",
    ")\n",
    " # loading validation data (automatically replaced by test data when run on tira)\n",
    "text_validation = tira.pd.inputs(\n",
    "        \"nlpbuw-fsu-sose-24\", \"language-identification-validation-20240429-training\"\n",
    ")\n",
    "targets_validation = tira.pd.truths(\n",
    "        \"nlpbuw-fsu-sose-24\", \"language-identification-validation-20240429-training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latin = ['af', 'az', 'cs', 'da', 'de', 'en', 'es', 'fi', 'fr', 'hr', 'it', 'nl', 'no', 'pl'] # '0041-024F'\n",
    "cyrillic = ['bg', 'ru'] # '0400-04FF', '0500-052F'\n",
    "non_latin_blocks = {'el': '0370-03FF', 'zh': '4E00-9FFF', 'ko': 'AC00-D7AF', 'ur': '0600-06FF'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block(*ranges):\n",
    "    block = []\n",
    "    for r in ranges:\n",
    "        r = r.split('-')\n",
    "        block += list(range(int(r[0], 16), int(r[1], 16) + 1))\n",
    "    return block\n",
    "\n",
    "def comp_freq(text, block):\n",
    "    encoded = np.array([ord(c) for c in text])\n",
    "    return np.sum(np.isin(encoded, block)) / len(encoded)\n",
    "\n",
    "freq_vec = np.vectorize(comp_freq, excluded={1})\n",
    "\n",
    "def is_latin(texts):\n",
    "    latin_block = get_block('0041-024F')\n",
    "    freqs = freq_vec(texts, latin_block)\n",
    "    return freqs > 0.5\n",
    "\n",
    "def is_cyrillic(texts):\n",
    "    cyrillic_block = get_block('0400-04FF', '0500-052F')\n",
    "    freqs = freq_vec(texts, cyrillic_block)\n",
    "    return freqs > 0.5\n",
    "\n",
    "def classify_remainders(texts):\n",
    "    langs = np.array(list(non_latin_blocks.keys()))\n",
    "    freqs = np.empty(shape=(texts.shape[0], len(langs)))\n",
    "    for i, lang in enumerate(langs):\n",
    "        block = get_block(non_latin_blocks[lang])\n",
    "        freqs[:, i] = freq_vec(texts, block)\n",
    "    preds = langs[np.argmax(freqs, axis=1)]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999253125"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_latin = is_latin(text_train['text'])\n",
    "truth = np.isin(targets_train['lang'], latin)\n",
    "acc_latin = np.sum(pred_latin == truth) / len(pred_latin)\n",
    "acc_latin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985713838806219"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_non_latin = text_train['text'][~pred_latin]\n",
    "targets_non_latin = targets_train['lang'][~pred_latin]\n",
    "pred_cyrillic = is_cyrillic(text_non_latin)\n",
    "truth = np.isin(target_non_latin, cyrillic)\n",
    "acc_cyrillic = np.sum(pred_cyrillic == truth) / len(pred_cyrillic)\n",
    "acc_cyrillic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_remainders = text_non_latin[~pred_cyrillic]\n",
    "pred_remainders = classify_remainders(text_remainders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972975928269053"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_remainders = targets_non_latin[~pred_cyrillic]\n",
    "acc_remainders = np.sum(pred_remainders == targets_remainders) / len(pred_remainders)\n",
    "acc_remainders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
